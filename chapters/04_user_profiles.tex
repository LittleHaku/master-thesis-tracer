% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{User Profile Structure and Generation}\label{chapter:user-profiles}

Once the model is complete,
we use it to automatically generate user profiles for SENSEI.
These serve as test cases designed to verify
the discovered functionalities of the chatbot,
its handling of different inputs,
to check if the outputs match the expected values,
and to identify other errors such as timeouts.

First, \autoref{sec:profile-structure}
covers the structure of these profiles and how they work;
then \autoref{sec:profile-generation}
details how these profiles are synthesised from the inferred model.


\section{User Profiles Structure}\label{sec:profile-structure}

A user profile contains all the information
that characterises the user,
the conversation goals,
interaction style,
and other information such as the \ac{LLM} that will be used,
or the number of conversations and turns per conversation.
These profiles are structured in a YAML file,
\autoref{code:yaml-profile-pizza} and \autoref{code:yaml-profile-drinks}
show an example of the user profiles generated during a \ac{TRACER} execution
against a pizzeria chatbot made with Taskyto.

\lstinputlisting[
  language=yaml,
  caption={Example of the first user profile generated for a pizzeria chatbot.},
  label={code:yaml-profile-pizza}
]{code/pizza_orderer_and_customizer.yaml}

\lstinputlisting[
  language=yaml,
  caption={Example of the second user profile generated for a pizzeria chatbot.},
  label={code:yaml-profile-drinks}
]{code/drink_orderer.yaml}



To better understand how the profiles are generated,
we must first understand the profiles and their structure.
Each profile consists of the \texttt{test\_name},
a unique identifier for the profile,
followed by four configuration blocks:
\texttt{llm}, \texttt{user}, \texttt{chatbot} and \texttt{conversation}.

\subsection{LLM Configuration (\texttt{llm})}

This section specifies the \acl{LLM} to be used and its temperature.
The chosen \texttt{model} impacts the results,
as each model has its own strengths and limitations,
and some models will perform better than others,
usually at a higher cost.
This field (line 3 in the listings) takes the name of the model
(e.g., \texttt{gpt-4o-mini}).
Next is the \texttt{temperature} (line 4),
a parameter that controls the randomness of the \ac{LLM};
that is, how randomly the model selects the next word.
A value of 0 makes the model's output deterministic,
while a value of 1 encourages more creative responses.
Lastly, lines 5 and 6 specify the format type,
which can be set to audio or text.

\subsection{User Persona Definition (\texttt{user})}

A key concept in these profiles is the persona,
a detailed, fictional character that represents a primary user type
\autocite{cooperFaceEssentialsInteraction2014}.
Personas encapsulate the goals, motivations, and behaviours of real users.

In the \texttt{user} section of a test profile
(starting in line 7 in both listings),
we define such a persona for the simulated user
through a combination of several fields.
We start with the \texttt{language} that the user will employ,
followed by the \texttt{role} of the simulated user,
that is, a sentence representing the user's identity and objective
(e.g., A customer ordering a pizza).
The \texttt{context} field provides additional information to the chatbot,
it can add more details or personality traits, such as,
"You are in a hurry", to make the simulated user more realistic.
The \texttt{goals} field is arguably the most important of the user's fields,
as it describes all the objectives for the conversation.
These objectives are written like templates with placeholders
(e.g., Specify the pizza size as {{pizza\_size}}).
Below the list with all the objectives
is the list of parameters, which is the placeholders defined in the goals.
Each of these parameters is assigned a function:
\begin{itemize}
  \item \texttt{random()}: A random value from the data below is selected.
  \item \texttt{random(x)}: Takes $x$ different random values.
  \item \texttt{forward()}: Selects one value sequentially from the data list
    (see \autoref{code:yaml-profile-pizza} lines 21 and 35
    and \autoref{code:yaml-profile-drinks} lines 20 and 27).
  \item \texttt{forward(x)}: Takes the $x$ next values sequentially.
  \item \texttt{forward(var)}:
    Allows to cycle through all the combinations of a pair (or more, depending on the nested combinations) of variables.
    For example, one could nest pizza sizes with pizza types,
    that means that all combinations of pizza sizes with pizza types would be tested,
    that is, small pepperoni, small four cheese, ..., medium pepperoni, medium four cheese, ..., large pepperoni, large four cheese...
\end{itemize}
After the function, we can specify its \texttt{type},
with values such as int, float, string or date.
Next, there is the data field,
where a list of values is provided
or if it is a numeric value, a range with min and max
and the step to go from the min to the max.
For example, on both inputs in \autoref{code:yaml-profile-pizza}
in lines 20 and 34 we have inputs with strings
that right below define a list of values that
the forward function will take.
In \autoref{code:yaml-profile-drinks} in line 19
we have an input variable with an integer,
note that instead of a list of values,
the parameters now include a minimum, maximum, and step.

\subsection{Chatbot Settings (\texttt{chatbot})}

This section specifies the expected behaviour of the system under test.
First we have the \texttt{is\_starter},
which defines whether the chatbot initiates the conversation.
The second field is the \texttt{fallback}
(\autoref{code:yaml-profile-pizza} line 44
and \autoref{code:yaml-profile-drinks} line 36),
this is the default sentence given by the chatbot
when it cannot understand the user's statement,
or the user's input is outside of the chatbot's scope.

Next is the \texttt{outputs} field, which is similar to the \texttt{goals} field
but is used to extract outputs from the chatbot rather than define user inputs.
For each output a name is provided
then a \texttt{type} which can be string, money, int, float or date;
then we have a short \texttt{description}.
This information will be used by an \ac{LLM}
to extract the information from the conversation with the chatbot.

For example, in \autoref{code:yaml-profile-pizza} we have on line 46
\texttt{pizza\_type\_list} which will extract from the conversation
the list of available pizzas provided by the chatbot,
since it is a list of pizzas it is defined as string.
In the \autoref{code:yaml-profile-drinks} we have
\texttt{drink\_option\_price} in line 44,
which will extract the price a single drink,
note how it uses the type money,
and, lastly, in the same listing in line 47
we have \texttt{drink\_quantity\_requested}
which will extract the number of drinks
and for this, the type is set to int.


\subsection{Conversation Control (\texttt{conversation})}

This last section controls aspects of the execution.
The \texttt{number} will control the number of times the conversation will take place,
the more conversations, the more combinations of the goals' items to be tested.
This field allows an integer, that simply indicates the number of conversations;
\texttt{all\_combinations} that will exhaustively test every combination,
although it ensures good coverage of the inputs,
it can also result in an enormous number of test cases,
especially if we use nested forwards;
\texttt{sample(x)}, where $x$ is a number between $0$ and $1$,
will compute all the possible combinations
and take a percentage of all of these.

The second field, \texttt{goal\_style}, is the test's stop condition.
It can be the number of steps taken in the conversation
(let a step be a user message followed by a chatbot's one),
or \texttt{all\_answered} which will stop once the user has completed all of its goals,
this parameter is also accompanied by a \texttt{limit} field which sets a hard limit
ensuring that the conversation finishes even if the chatbot is not able to fulfil the user's goals.

Lastly, we have the \texttt{interaction\_style},
which lets us set a list of styles that the simulated user will adopt for its conversations.
These styles are predefined and include some like
\textit{make spelling mistakes}, \textit{use short phrases}
or \textit{single question}.

See from line 76 onwards in \autoref{code:yaml-profile-pizza}
and from line 59 onwards in \autoref{code:yaml-profile-drinks}
to see a real example.

\section{User Profile Generation}\label{sec:profile-generation}

\begin{figure}[htpb]
    \centering
    \input{figures/profile-generation-steps.tex}
    \caption{Process to generate profiles from the model to the final user profiles.}
    \label{fig:profile_generation_flowchart}
\end{figure}

The profile generation is an automated process
that aims to convert the inferred model
into a set of profiles that will thoroughly test the chatbot.
The process is divided into seven steps that can be visualised in \autoref{fig:profile_generation_flowchart}.
It begins by
grouping functionalities into profiles,
followed by the \ac{LLM}-driven generation of goals, variables, context, and outputs.
This is followed by the definition of the conversation style and,
finally, the profile assembly and validation step.
Each of these steps is detailed in the following subsections.

\subsection{Grouping Functionalities into Profiles}

The inferred model is sent to an \ac{LLM} along with conversation fragments,
with this information the \ac{LLM} is prompted to
group the functionalities into realistic and logical user scenarios.
Each group will gather functionalities that are semantically related,
frequently used together or performed sequentially.
Ideally, each functionality is only assigned to one group
to ensure that all functionalities are used while avoiding redundancy;
this is not always achieved since in cases where a functionality branches into others
it is required to go through it at least twice.
From these functionality groups, the \ac{LLM} will generate
the \texttt{test\_name} along with its \texttt{role}.

\subsection{Goal Generation}

Once the functionalities are grouped,
the group of functionalities is sent to a new \ac{LLM} call
that will create a set of functionalities that when fulfilled
will ensure that the functionalities have been activated.
The goals may or may not have variables,
it will depend on the nature of the goal,
for example, a query about opening hours will not require variables
but if the goal is about asking for a pizza,
then the goal will likely have variables.

\subsection{Variable Generation}

This step is only required when variable \texttt{\{\{placeholders\}\}} have been defined.
To understand how the variables are generated
first we need to define what a data source is.
A data source comprises the values of either a parameter or an output from a functionality node,
we decided to use both outputs and parameters,
as there are occasions where the extracted functionality is,
for example, "list available pizza types"
and the values that we can use for the variables
are in the outputs instead of the more obvious parameters.
So the data sources are the combinations of all the values
from all outputs and parameters.

With this defined, the procedure is as follows for each individual variable.
First, we pass all these data sources to the \ac{LLM}
and prompt it to match the variable to one of the data sources
emphasizing that it is not necessary to force a match unnecessarily.
Then, if one match is given,
we request the \ac{LLM} to generate another extra value
based on the content of the returned data source
to test the chatbot on values outside of the ones that it suggests.
For example, with the pizza sizes small, medium, large,
it tends to generate extra large as the extra value,
or instance, \texttt{pineapple} was generated as a topping in this case
(see \autoref{code:yaml-profile-pizza})

In the case that no data source is matched,
either because the chatbot didn't provide values
(for example with dates or numbers)
or because the data source matching didn't correctly match the variable,
the \ac{LLM} will generate the data for the variable given
the goals, functionalities, role and conversations.
It is important to note that variables are not only restricted to be strings,
in the \autoref{code:yaml-profile-drinks} the drink quantity
is a great example of variables generated
with numeric values instead of being strings or matched data sources.

The generated variables always use the \texttt{forward()} function
since it allows us to test every option.
We chose this over the nested approach
since it has a great balance between completeness and number of conversations.
For example, having $8$ pizza types with $3$ different pizza sizes
with nested forwards would require $8 \cdot 3 = 24$ conversations,
while using the regular forward would require only $8$ conversations
to go through all the options.

\subsection{Context Generation}

A simple context of two or three sentences
is generated by the \ac{LLM} based on
the functionalities, the previously generated content and the conversations.
The idea of the generated context is to create a more realistic scenario
where the user is not simply testing the chatbot
but in a realistic case where for example
the user is at a get-together and is looking to order pizzas,
or is an Erasmus student requesting help to a university chatbot.

\subsection{Output Definition}

The output definition along with the goal and variables is one of the key steps.
This allows the chatbot to be tested
and see if the chatbot is returning the information that it should
and thus completing its functionalities.
The outputs are generated by the \ac{LLM}
taking into account the functionality and the goals,
seeking to identify elements that confirm their achievement,
like for example the order ID or the order price;
and by also looking at the outputs from the functionality nodes.
The \autoref{code:yaml-profile-drinks} contains great examples
of outputs of different types such as money, int or string.

These outputs are as granular as possible
to allow for a better testing of the chatbot,
for example, instead of a more vague output like
"order confirmation", it would be split into two granular outputs
"order ID" and "total order price".

\subsection{Conversation Style Definition}

The \texttt{conversation} section does not require \ac{LLM} calls.
First, the number of conversations is chosen
based on the variable with the largest data set,
for instance, if we have four variables,
and pizza type, with $8$ options, is the one with the larger set of options,
the number of conversations will be $8$ to ensure that all the variables are tested.

For the length of the conversation,
a limit is set on a linear combination
of the number of goals and outputs,
so that the greater the number of goals and outputs,
the longer the conversation will be,
but still with a hard limit of $30$.

Lastly, the interaction style always is set to \texttt{single\_question}
since otherwise the user simulator tries to
fulfil all the goals at the same time
and results in awkwardly complex sentences.

\subsection{Profile Assembly and Validation}

Once all the fields have been generated
the profile is assembled into a YAML file.
This profile is then passed through a validation script
that will check that all the required fields are complete,
that every placeholder has a variable defined,
and that each variable is correctly defined
amongst other checks,
and if any error appears it will return a verbose description of the issue.
Then, the description of these errors along with the YAML file
are sent to the \ac{LLM} with a prompt to fix the issue.


These seven steps allow us to transform the inferred model
from the deployed chatbot under test,
into a set of realistic and comprehensive user profiles
that will act as test cases when combined with the user simulator SENSEI.
This profile generation stage bridges the gap between
black-box model inference and automated testing.
