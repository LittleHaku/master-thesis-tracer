% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Background and State of the Art}\label{chapter:state_of_the_art}

This chapter details the technical foundations
for the research presented in this thesis
and reviews the relevant literature in the field.
It is structured into two primary sections.
The first, the \textbf{Background},
introduces the core concepts essential to this work,
including conversational agents, \aclp{LLM}, black-box testing,
and the diverse development frameworks used to build them.
The next section, the \textbf{State of the Art},
provides a review of this literature,
focusing on chatbot testing methodologies,
user simulation techniques, and black-box model inference.

\section{Background}\label{sec:background}

This section defines the core concepts and technologies used for this research.
It covers conversational agents,
\aclp{LLM}, the principles of black-box testing,
and the main development frameworks for conversational agents relevant to this work.

\subsection{Conversational Agents}

Conversational agents, commonly referred to as chatbots,
are software systems designed to interact with users through natural language dialogue.
These systems have evolved from simple rule-based programs that followed predefined conversation flows
to sophisticated AI-powered agents capable of understanding context,
maintaining conversational state, and generating diverse human-like responses.

Modern conversational agents can be categorized into two main types
given the domain and range of their capabilities.
\begin{itemize}
  \item \textbf{Task-oriented:}
    Task-oriented agents are designed to assist users in completing specific tasks,
    such as booking appointments, processing orders, or providing customer support.
    These systems typically follow structured conversation flows
    and maintain explicit state management to track task progress.
    Examples of these chatbots are
    UAM's assistant Ada \autocite{AdaUAM}.
    or chatbots made with the framework Taskyto \autocite{sanchezcuadradoAutomatingDevelopmentTaskoriented2024}

  \item \textbf{Open-domain:}
    in contrast, open-domain chatbots
    engage in general conversation without specific task constraints,
    aiming to provide informative, helpful, or entertaining interactions across a wide range of topics.
    These are chatbots like ChatGPT \autocite{ChatGPT} or Gemini \autocite{GoogleGemini}.
\end{itemize}

The development of these conversational agents
has been facilitated by various frameworks and platforms.
\begin{itemize}
  \item \textbf{Intent-based frameworks:}
    these frameworks such as Google's Dialogflow \autocite{Dialogflow} or Rasa \autocite{Rasa2020}
    enable developers to define conversation flow through intents, utterances, and responses.
    These platforms have low latency and deterministic behaviour
    but are very rigid, struggle to scale,
    and to work properly require a big corpus to be trained on.

  \item \textbf{Multi-agent programming environments:}
    these systems like LangGraph \autocite{LangGraph} or Microsoft's AutoGen \autocite{AutoGen},
    allow for the creating of complex conversational systems
    where multiple \ac{AI} agents collaborate to process the user's request.
    These frameworks make use of the capabilities of \acp{LLM}.
    While they are less rigid than the previous ones,
    they can suffer from hallucinations,
    higher latency, and since they are not deterministic,
    getting out of the scope, and thus, making it harder to test it.
\end{itemize}

\subsection{\aclp{LLM}}

\aclp{LLM} represent an important advancement in \acl{NLP},
enabling conversational agents to understand and generate human-like text
without explicit programming of conversational rules like in intent-based frameworks.
These models, trained on a vast amount of text data,
have demonstrated remarkable capabilities in
language understanding \autocite{liEnhancingNaturalLanguage2024}, generation, and reasoning across diverse domains.

\aclp{LLM} are built employing transformers,
an architecture proposed by Vaswani et al. \autocite{vaswaniAttentionAllYou2017}.
This architecture's main innovation is the self-attention mechanism,
which allows the model to weight the importance of the words in the input,
allowing the model to capture longer dependencies and understanding the context.
These models are usually trained in two phases,
the first one, the pre-training,
is a self-supervised stage where the model
is fed with a vast amount of text,
where the model learns 
general relationships between words,
language patterns, facts and reasoning patterns.
Following this, the next stage is the fine-tuning,
where the model is fed with a curated dataset
that aligns with the model's purpose (e.g., medical or coding),
also using techniques such as
Reinforcement Learning from Human Feedback (RLHF)
which helps the model to give responses
that align better with human preferences.
This process has made possible models like
OpenAI's GPT series (e.g., GPT-4) \autocite{OpenAI2025},
Google's Gemini series \autocite{GoogleGemini},
Meta's open-source Llama Series \autocite{touvronLLaMAOpenEfficient2023},
or Anthropic's Claude models \autocite{ClaudeAnthropic}.


The integration of \acp{LLM} into conversational agents
has transformed the way humans interact with computers.
Unlike traditional rules-based systems that rely on predefined patterns and responses,
\ac{LLM}-powered chatbots can engage in natural conversations,
even keeping context about what the user said before.
However, this flexibility comes with challenges,
specially for testing and validation.
The non-deterministic nature of \acp{LLM} means that
identical inputs may produce different outputs across multiple interactions.
This complicates traditional assertion-based testing,
which relies on fixed, predictable outcomes.
While assertions can still be used
to check for high-level properties or the presence of key information,
they cannot easily validate the exact phrasing of a response.
Furthermore, the ability of \ac{LLM}-powered agents
to maintain context across multiple turns
means that the system's state space increases dramatically with conversation length,
as the response depends not just on the immediate input
but on the entire preceding dialogue history.

The emergent behaviour of \ac{LLM}-powered systems further complicates testing efforts.
These systems can demonstrate capabilities
that were not explicitly programmed by their developers,
making it difficult to define the complete functional scope of the agent.
A particularly problematic form of this emergent behaviour is hallucination,
where the model generates responses that are
factually incorrect, nonsensical, or ungrounded in the provided context.
Such behaviour is especially dangerous in high-stakes domains
where misinformation can have severe consequences.
When these unpredictable behaviours are combined
with the virtually infinite ways a user can
phrase an intent or introduce unexpected topics,
it becomes impossible to achieve adequate test coverage through manual scripting.

\subsection{Black-box Testing}

Black-box testing is a software testing methodology
where the internal structure, implementation details, and source code of the system under test
are unknown or inaccessible to the tester.
This approach focuses on validating system behaviour based solely on inputs and outputs,
treating the system as an opaque "black box."
In practice, this involves interacing with the chatbot as a real user would:
asking questions about capabilities
(e.g., "What are you business hours?"),
attempting to complete a task
(e.g., "I'd like to order a pizza"),
or providing unexpected inputs to check its error handling
(e.g., "Can you book me a flight to the moon?").

The accessibility advantage of black-box testing
is particularly relevant for deployed chatbots,
which are typically accessed via public \acp{API} or web interfaces.
This mirrors real-world usage
and enables testing of production systems without special access.


However, this approach involves trade-offs.
By not having access to the source code,
testers lose the ability to use powerful white-box techniques
such as measuring code coverage to assess test suite thoroughness
or using debuggers to pinpoint the exact source of a fault.
The challenge, therefore, is
to maximize the effectiveness of testing
despite these limitations.
The exploration problem involves
systematically discovering the full range of functionalities,
while the validation challenge requires
determining if responses are correct
without access to internal specifications.

\subsection{Development Frameworks}

When it comes to building conversational agents
there exists a diverse way of building them.
In this section we are going to cover three paradigms,
intent-based frameworks, that rely on predefined conversation patterns;
multi-agent programming frameworks, that use the power \acp{LLM};
and \aclp{DSL} that provide a declarative approach.

\subsubsection{Intent-Based Frameworks}

Google's Dialogflow \autocite{Dialogflow}
is one of the most used intent-based frameworks.
It offers a visual interface
for designing conversational flows
through intents (e.g., order a pizza),
entities (e.g., pizza size and type)
and the fulfillment logic that executes when an intent is recognized.
When designing it, on top of the intents,
one must also provide examples of how the user can express things
and how the chatbot would answer,
this makes it very difficult to scale
as the more intents we have,
the more training examples we need to create.

Rasa \autocite{Rasa2020} offers and open-source \autocite{RasaHQRasa2025} alternative.
The architecture is divided into two sections:
the \ac{NLU} and the Core.
It utilizes machine learning to train a pipeline
for intent classification and entity extraction.
Although it allows to create more complex chatbots,
the missing visual interface creates a steeper learning curve.

\subsubsection{Multi-Agent Programming Environments}

LangGraph \autocite{LangGraph} is one of the main exponents
of this new frameworks that leverage the use of \ac{LLM}
to create complex conversational systems.
As the name says, LangGraph is made up by a graph
where nodes are \ac{AI} agents or tools
and edges control the flow of information between the nodes.
This allows for more dyncamic conversational flows
than traditional intent-based systems,
and also allow to break a complex problem into different agents.
However, implementing all of this is not trivial
and requires proper orchestration of all the agents
and also comes with the risk of \acp{LLM}'s non-deterministic behaviour.

Similarly, Microsoft's AutoGen \autocite{AutoGen}
enables the development of multi-agent systems
where different \ac{AI} agents collaborate to complete complex tasks.
This allows to follow a divide and conquer approach
where each agent is a specialized \ac{AI} agent.
For example, one could have a planner agent,
that would divide the user's petition into bite-sized tasks
and send each to the agent that better suits the task.

\subsubsection{\aclp{DSL}}

A \acl{DSL} is a computer language
specialized for a particular application domain.
In the context of conversational AI,
\acp{DSL} provide high-level abstractions
that allow developers to define chatbot behaviour declaratively,
focusing on the 'what' rather than the 'how'.
While a deep understanding of any single framework
is not essential for this thesis's work,
a brief overview of the Taskyto framework
\autocite{sanchezcuadradoAutomatingDevelopmentTaskoriented2024}
is valuable context for the evaluation
detailed in Chapter \ref{chapter:evaluation}.

Taskyto utilizes a YAML-based \ac{DSL}
to define the structure and logic of task-oriented chatbots.
A chatbot's definition is composed of a collection of modules which,
can be broadly categorized into two types:


\begin{itemize}
    \item \textbf{Functional Modules:}
      These modules define the interactive,
      task-oriented workflows of the chatbot.
      The Taskyto DSL provides several types of functional modules
      to construct complex conversations, including:
      `menu` modules for offering conversational alternatives to the user;
      `sequence` modules for defining multi-step processes;
      `data gathering` modules for requesting specific user input (slots);
      and `action` modules for executing business logic, often written in Python.

    \item \textbf{Question-Answering (QA) Modules:}
      These modules are designed to handle informational, FAQ-style queries.
      Each QA module contains
      a list of predefined user questions
      and their corresponding answers.
      This allows the chatbot to respond
      to common informational requests
      outside of its primary task-oriented flows.
\end{itemize}

This modular and declarative architecture
is what makes the Taskyto framework particularly well-suited
for the experimental validation of TRACER,
as detailed in Chapter \ref{chapter:evaluation}.
The separation of the chatbot's capabilities into discrete modules
allows us to track which modules
(and fields of these modules)
were activated during a conversation,
that way, we can precisely measure the coverage
achieved by \ac{TRACER}.
Furthermore, the declarative YAML structure
simplifies the systematic introduction of faults,
facilitating the creation of a large set of mutants
for our mutation testing analysis,
which is essential for evaluating
the fault-detection effectiveness of the generated profiles

\indent

In summary,
the field of conversational \ac{AI} is characterized by diverse agent types,
powered by advancements in \acp{LLM},
and built using heterogeneous development paradigms,
from structured \acp{DSL} to flexible multi-agent frameworks.
This context, combined with the necessity of treating many deployed systems as black boxes,
defines the complexity in which any modern testing methodology must operate.
The following section will review the state of the art in testing approaches designed to address these challenges.

\section{State of the Art}\label{sec:sota}

The testing of conversational agents presents unique challenges
that have attracted research attention in recent years.
This section reviews the current state of the art in
chatbot testing methodologies, model learning approaches, and user simulation techniques.

The analysis is structured into three key areas.
First, we examine the foundational field of model learning
and black-box modeling to provide context for TRACER's core approach.
Second, we survey the existing methodologies for chatbot testing,
categorizing them based on their required artifacts and level of automation.
Finally, we delve into the specific techniques for user simulation,
a critical component of automated testing.
Through this analysis, we identify the research gaps that this thesis aims to address.

\subsection{Model Learning and Black-Box Reverse Engineering}

Inferring a model of a software system by observing its external behaviour,
without access to its internal structure,
is a well-established discipline known by various terms including
model learning, automated model inference, black-box modeling, or dynamic reverse engineering.
This approach has been successfully applied in diverse areas of software engineering,
such as general software testing \autocite{aichernigModelLearningModelBased2018},
system reverse engineering \autocite{hajipourIReEnReverseEngineeringBlackBox2021, menguyBlackboxCodeAnalysis2023},
and network protocol inference \autocite{luoDynPREProtocolReverse}.

Traditional model learning techniques,
such as those demonstrated by Muzammil et al. \autocite{shahbazAnalysisTestingBlackbox2014},
often focus on automatically inferring finite state machines.
Similarly, the reverse engineering techniques applied by Walkinshaw et al. \autocite{walkinshawReverseEngineeringSoftwareBehavior2013}
extract behavioural models through dynamic analysis.
These methods have proven effective for systems with discrete and well-defined input/output alphabets.

However, these classical approaches
face limitations when applied to modern conversational agents.
The infinite input space of natural language,
the non-deterministic nature of \ac{LLM}-powered systems,
and the complex, context-dependent state of a conversation
make traditional model learning techniques inadequate.
Consequently,
adapting these principles to automatically generate
comprehensive, functional models of chatbots for test synthesis
remains a largely unaddressed challenge in the literature.

\subsection{Methodologies for Chatbot Testing}

The field of chatbot testing has evolved along several distinct paths,
each addressing different aspects of the validation challenge.
A comprehensive survey by Ren et al. \autocite{renEvaluationTechniquesChatbot2019} highlights the difficulties
in defining appropriate metrics and methodologies for these complex systems.

\subsubsection{Manual and Corpus-Based Testing}

The earliest and most direct approaches to chatbot testing
rely on manual effort and existing conversation corpora.
Manual testing, while essential for assessing usability,
is resource-intensive and difficult to scale.
A recent example is GastroBot,
a \ac{RAG} chatbot where manual assessment by medical experts
was a key part of its evaluation \autocite{zhouGastroBotChineseGastrointestinal2024}.
While this provides expert-level validation,
it highlights the persistence of manual methods
that are inherently subjective, resource-intensive,
and unscalable for comprehensive regression testing.

To introduce automation, frameworks like Bottester
\autocite{vasconcelosBottesterTestingConversational2017}
use existing Q\&A corpora.
The main limitation of this approach
is its complete dependence on
the quality and comprehensiveness of the pre-existing dataset;
if a conversational path is not in the corpus, it cannot be tested.
Similarly, commercial platforms like Cyara \autocite{CyaraBotium}
and Rasa's testing framework \autocite{RasaTest2025}
require the manual specification of test conversations and expected outcomes.
These approaches are primarily confirmatory,
designed to verify known behaviours rather than explore the unknown,
and they struggle to scale to the dynamic nature of modern agents.

\subsubsection{Static Analysis and White-Box Testing}

For scenarios where source code is available,
white-box techniques offer more rigorous validation.
Cuadrado et al. \autocite{cuadradoIntegratingStaticQuality2024}
propose static quality analysis techniques
that inspect the structural properties of a chatbot's implementation.
To assess test adequacy, Cañizares et al.
\autocite{canizaresCoveragebasedStrategiesAutomated2024}
develop coverage-based strategies that
require access to the chatbot's internal structure to compute metrics.

Mutation testing, a powerful technique for assessing test suite quality,
has also been adapted for chatbots.
Gómez-Abajo et al. \autocite{gomez-abajoMutationTestingTaskOriented2024}
propose mutation operators specifically for task-oriented chatbots like Taskyto \autocite{sanchezcuadradoAutomatingDevelopmentTaskoriented2024},
while Urrico et al. \autocite{urricoMutaBotMutationTesting2024} introduce MutaBot,
a dedicated mutation testing framework for platforms like Dialogflow \autocite{Dialogflow},
While these white-box approaches provide rigorous validation
and deep insights into the system's internals,
their reliance on source code access
is their primary limitation.
They cannot be applied to the vast number of
proprietary or third-party chatbots
that must be treated as opaque black boxes.

\subsection{User Simulation for Automated Testing}

User simulation has emerged as a key strategy to
address the scalability challenges of chatbot testing
by automatically generating realistic user interactions.
The most recent approaches employ generative \acl{AI},
especially \acp {LLM}.

\subsubsection{Traditional and Corpus-Driven Simulation}

Early user simulation approaches
relied on statistical models and existing corpora.
Griol et al. \autocite{griolAutomaticDialogSimulation2013}
employed neural networks trained on dialogue corpora
to suggest user utterances.
The user simulation capabilities within Bottester
\autocite{vasconcelosBottesterTestingConversational2017}
are also configured with Q\&A corpora
and compute metrics on satisfaction and correctness.
The primary limitation of these methods is
their dependency on large, relevant datasets,
which may not be available or cover all necessary scenarios.

\subsubsection{LLM-Based User Simulation}

The arrival of \acp{LLM} has enabled a new generation
of highly flexible and realistic user simulators.
Researchers have demonstrated the ability
to simulate users with specific personality traits and behaviours.
For example, Ferreira et al. \autocite{ferreiraMultitraitUserSimulation2024}
generate profiles with traits like engagement and verbosity,
while Sekulic et al. \autocite{sekulicSimulatingConversationalSearch2024}
simulate users with varying levels of patience and politeness for conversational search.
Frameworks like CoSearcher \autocite{salleStudyingEffectivenessConversational2021}
also allow for tuning user cooperativeness.
These works prove the principle of creating diverse, persona-driven simulated users.

Other approaches focus on specific conversational behaviours.
Kiesel et al. \autocite{kieselSimulatingFollowUpQuestions2024}
simulate follow-up questions,
and the followQG framework \autocite{bImprovingAsynchronousInterview2021}
uses trained models to generate contextually relevant continuations.
More advanced frameworks leverage \acp{LLM} for even more complex tasks.
The Kaucus simulator \autocite{dholeKAUCUSKnowledgeAugmented2024}
incorporates external knowledge via retrieval augmentation,
and Terragni et al. \autocite{terragniInContextLearningUser2023}
generate user utterances directly from high-level goal descriptions.
Bandlamudi et al. \autocite{bandlamudiFrameworkEnableTest2024}
employ a dual-\ac{LLM} approach where
one \ac{LLM} simulates the user and
another judges the chatbot's response.
While this cleverly addresses the automated evaluation challenge,
it introduces the potential for biases from the judging LLM
and may not scale cost-effectively due to the computational overhead
of running two models for every interaction.
Finally, Wit \autocite{dewitLeveragingLargeLanguage2024}
demonstrates the practicality of using commercial APIs like ChatGPT
for low-cost testing of rule-based agents.

\subsubsection{The Profile Generation Bottleneck}
Despite the remarkable progress in creating sophisticated user simulators,
a critical challenge remains: the profile generation bottleneck.
The SENSEI simulator \autocite{delaraSensei},
used in this research, exemplifies this issue.
It is a powerful tool capable of executing highly detailed test profiles,
but its effectiveness is entirely dependent on the quality of those profiles.
Across the state of the art,
these essential input profiles are either created manually,
a process that is time-consuming and does not scale,
or generated from generic descriptions
that lack grounding in the specific functionalities of the chatbot under test.
For example, manually writing even a dozen comprehensive test profiles,
complete with varied user personalities, goals, and parameter combinations,
could take a skilled engineer several hours or even days of effort,
making it impractical for large-scale or continuous testing.
This creates a research gap
for a method that can automatically synthesize
rich, detailed, and targeted user profiles
based on a discovered model of the chatbot's actual capabilities.

\subsection{Summary and Identified Research Gaps}

To visually summarize the landscape,
Table \ref{tab:sota_comparison}
compares the testing paradigms discussed.

\begin{table}[h!]
\centering
\caption{Comparison of State-of-the-Art Chatbot Testing Paradigms}
\label{tab:sota_comparison}
\resizebox{\textwidth}{!}{
\begin{tabular}{@{}lllll@{}}
\toprule
\textbf{Paradigm} & \textbf{Requires Source Code?} & \textbf{Requires Corpus/Scripts?} & \textbf{Automation Level} & \textbf{Key Limitation} \\ \midrule
Manual Testing & No & No & Low & Unscalable, not reproducible \\
Scripted Testing & No & Yes (Manual Scripts) & Medium & High manual effort, brittle \\
Corpus-Based & No & Yes (Existing Corpus) & Medium & Dependent on corpus quality \\
White-Box Testing & Yes & No & High & Requires source code access \\
\textbf{TRACER} & \textbf{No} & \textbf{No} & \textbf{High} & \textbf{Addresses prior limitations}
\\ \bottomrule
\end{tabular}
}
\end{table}

Our review of the state of the art
reveals that while many valuable contributions have been made,
limitations persist.
The rapid evolution of conversational AI
has outpaced the development of
correspondingly advanced testing methodologies,
creating critical gaps in quality assurance capabilities.

This analysis identifies three primary research gaps in the current literature:
\begin{enumerate}
    \item \textbf{A Lack of Fully Automated, Framework-Agnostic Black-Box Testing:}
      There is a pressing need for a testing methodology
      that is framework-agnostic, that is,
      capable of operating on any deployed chatbot
      regardless of its underlying implementation
      (e.g., Rasa, Dialogflow, Taskyto, LangGraph, etc.).
      Existing methods are often tied to a specific technology
      or require manual artifacts like scripts or corpora,
      preventing a universal, automated approach.

    \item \textbf{An Unsolved Profile Generation Bottleneck:}
      The potential of advanced user simulators
      is currently constrained by the lack of an automated method
      to generate detailed, realistic test profiles.
      The high manual effort required to create such profiles
      constitutes a major barrier
      to the adoption of automated, simulation-based testing at scale.

    \item \textbf{The Absence of Applied Model Inference for Chatbot Testing:}
      The established principles of black-box model learning
      have not yet been effectively adapted and applied
      to the unique challenges of conversational \ac{AI}.
      There is a clear need for a technique
      that can automatically infer a rich, functional model of a chatbot
      through natural language interaction alone,
      for the express purpose of generating comprehensive test cases.

\end{enumerate}

This thesis directly addresses these interconnected gaps.
We propose \ac{TRACER}, a novel framework
that provides a fully automated black-box method
for chatbot model learning and test profile generation.
By requiring only \ac{API} access to a deployed chatbot,
\ac{TRACER} overcomes the limitations of existing approaches
and provides a comprehensive, end-to-end solution
for the automated testing of modern conversational agents.
