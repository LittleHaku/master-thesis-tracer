% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Background and State of the Art}\label{chapter:state_of_the_art}

This chapter details the technical foundations
for the research presented in this thesis
and reviews the relevant literature in the field.
It is structured into two primary sections.
The first, the \textbf{Background},
introduces the core concepts essential to this work,
including conversational agents, \aclp{LLM}, black-box testing,
and the diverse development frameworks used to build them.
The subsequent section, the \textbf{State of the Art},
provides a critical review of this literature,
focusing on chatbot testing methodologies,
user simulation techniques, and black-box model inference.
This analysis serves to identify the specific research gaps
that motivate the contributions of this work.

\section{Background}\label{sec:background}

This section defines the core concepts and technologies that underpin this research.
It details the nature of conversational agents,
the function of \aclp{LLM}, the principles of black-box testing,
and the key development paradigms relevant to this work.

\subsection{Conversational Agents}

Conversational agents, commonly referred to as chatbots,
are software systems designed to interact with users through natural language dialogue.
These systems have evolved from simple rule-based programs that followed predefined conversation flows
to sophisticated AI-powered agents capable of understanding context, maintaining conversational state, and generating human-like responses.

Modern conversational agents can be categorized into two main types
given the domain and range of their capabilities.
\begin{itemize}
  \item \textbf{Task-oriented:}
    Task-oriented agents are designed to assist users in completing specific tasks,
    such as booking appointments, processing orders, or providing customer support.
  These systems typically follow structured conversation flows
and maintain explicit state management to track task progress.
  Examples of these chatbots are Taskyto \autocite{sanchezcuadradoAutomatingDevelopmentTaskoriented2024} or UAM's assistant Ada \autocite{AdaUAM}.

  \item \textbf{Open-domain:}
  in contrast, open-domain chatbots
  engage in general conversation without specific task constraints,
  aiming to provide informative, helpful, or entertaining interactions across a wide range of topics.
  These are chatbots like ChatGPT \autocite{ChatGPT} or Gemini \autocite{GoogleGemini}.
\end{itemize}

The development of these conversational agents
has beeen facilitated by various frameworks and platforms.
\begin{itemize}
  \item \textbf{Intent-based frameworks:}
    these frameworks such as Google's Dialogflow \autocite{Dialogflow} or Rasa \autocite{Rasa2020}
    enable developers to define conversation flow through intents, utterances, and responses.
    These platforms have low latency and deterministic behavior
    but are very rigid, struggle to scale,
    and to work properly require a big corpus to be trained on.

  \item \textbf{Multi-agent programming environments:}
    these systems like LangGraph \autocite{LangGraph} or Microsoft's AutoGen \autocite{AutoGen},
    allow for the creating of complex conversational systems
    where multiple \ac{AI} agents collaborate to process the user's request.
    These frameworks make use of the capabilities of \acp{LLM}.
    While they are less rigid than the previous ones,
    they can suffer from hallucinations, 
    higher latency, and since they are not deterministic,
    getting out of the scope, and thus, making it harder to test it.
\end{itemize}

\subsection{\aclp{LLM}}

\aclp{LLM} represent a significant advancement in \acl{NLP},
enable conversational agents to understand and generate human-like text
without explicit programming of conversational rules like in intent-based frameworks.
These models, trained on a vast amount of text data,
have demonstrated remarkable capabilities in
language understanding \autocite{liEnhancingNaturalLanguage2024}, generation, and reasoning across diverse domains.

The integration of \acp{LLM} into conversational agents
has transformed the way humans interact with computers.
Unlike traditional rules-based systems that rely on predefined patterns and responses,
\ac{LLM}-powered chatbots can engage in natural conversations,
even keeping context about what the user said before.
However, this flexibility comes with challenges,
specially for testing and validation.
The non-deterministic nature of \acp{LLM} means that
identical inputs may produce different outputs across multiple interactions,
This invalidates traditional assertion-based testing,
where a test case is expected to pass or fail based on a fixed, predictable outcome.
Furthermore, the ability of \ac{LLM}-powered agents
to maintain context across multiple turns
means that the system's response depends not just on the immediate input,
but on the entire preceding conversation history,
exponentially increasing the number of states that need to be validated.

The just mentioned behavior exhibited by \ac{LLM}-powered systems
further complicates testing efforts.
These systems can demonstrate capabilities that were not explicitly programmed,
making it difficult to predict all possible conversation paths and outcomes.
This phenomenon means that the functional scope of the agent is not fully known,
even to its developers.
When these mergent capabilities are combined
with the virtually infinite ways that a user can introduce the same intent
or introduce new topics,
it becomes impossible to achieve adequate test coverage through manual scripting.

This unpredictability necessitates new approaches to testing
that can systematically explore the space of possible interactions
and validate system behavior across diverse scenarios.

\subsection{Black-box Testing}

Black-box testing is a software testing methodology
where the internal structure, implementation details, and source code of the system under test
are unknown or inaccessible to the tester.
This approach focuses on validating system behavior based solely on inputs and outputs,
treating the system as an opaque "black box."

In the context of conversational agents,
black-box testing presents an interesting opportunity.
The accessibility advantage of black-box testing
is particularly relevant for deployed chatbots,
where users and testers typically interact with systems
through \acp{API} or web interfaces without access to underlying code or configuration.
This mirrors real-world usage scenarios
and enables testing of production systems
without requiring special access privileges or development environment setup.


However, black-box testing of conversational agents faces unique challenges.
The exploration problem involves
systematically discovering the full range of functionalities
and conversation paths supported by the chatbot.
Unlike traditional software systems with well-defined \acp{API},
conversational agents accept natural language input,
making the input space virtually infinite.
The validation challenge requires determining
whether chatbot responses are correct, appropriate, and helpful
without access to specifications or expected behavior definitions.

\subsection{\aclp{DSL} for Chatbot Development}

A \acl{DSL} is a computer language
specialized for a particular application domain.
In the context of conversational AI,
\acp{DSL} provide high-level abstractions
that allow developers to define chatbot behavior declaratively,
focusing on the 'what' rather than the 'how'.

The Taskyto framework \autocite{sanchezcuadradoAutomatingDevelopmentTaskoriented2024} is a prime example of this approach,
utilizing a YAML-based \ac{DSL} for creating task-oriented chatbots.
This design allows developers to specify
different modules in a structured and human-readable format.

Within Taskyto's \ac{DSL}, developers define a chatbot using a series of modules,
and actions with Python to execute business logic.
This modular, declarative structure
will be relevant when discussing the white-box evaluation and mutation testing of \ac{TRACER} in Chapter \ref{chapter:evaluation}.

\subsection{Multi-Agent Programming Environments}

An alternative paradigm for building complex conversational systems
involves the use of multi-agent environments,
where multiple specialized \ac{AI} agents collaborate to fulfill a user's request.
This approach employs the power of \acp{LLM}
by breaking down a complex problem into smaller tasks handled by different agents.

LangGraph \autocite{LangGraph} is a prominent library for implementing such systems.
It allows developers to define the collaborative workflow as a state graph,
where nodes represent individual agents (or tools)
and edges control the flow of information and execution between them.

This graph-based orchestration enables the creation of
sophisticated and flexible conversational patterns
that can involve complex reasoning and dynamic decision-making.
These agents present a different set of characteristics
compared to the more structured \ac{DSL}-based approach.

\indent

In summary,
the field of conversational \ac{AI} is characterized by diverse agent types,
powered by advancements in \acp{LLM},
and built using heterogeneous development paradigms,
from structured \acp{DSL} to flexible multi-agent frameworks.
This context, combined with the necessity of treating many deployed systems as black boxes,
defines the complex landscape in which any modern testing methodology must operate.
The following section will review the state of the art in testing approaches designed to address these challenges.

\section{State of the Art}\label{sec:sota}

The testing of conversational agents presents unique challenges
that have attracted significant research attention in recent years.
This section reviews the current state of the art in
chatbot testing methodologies, model learning approaches, and user simulation techniques.

The analysis is structured into three key areas.
First, we examine the foundational field of model learning
and black-box modeling to provide context for TRACER's core approach.
Second, we survey the existing methodologies for chatbot testing,
categorizing them based on their required artifacts and level of automation.
Finally, we delve into the specific techniques for user simulation,
a critical component of automated testing.
Through this analysis, we identify the research gaps that this thesis aims to address.

\subsection{Model Learning and Black-Box Reverse Engineering}

Inferring a model of a software system by observing its external behaviour,
without access to its internal structure,
is a well-established discipline known by various terms including
model learning, automated model inference, black-box modeling, or dynamic reverse engineering.
This approach has been successfully applied in diverse areas of software engineering,
such as general software testing \autocite{aichernigModelLearningModelBased2018},
system reverse engineering \autocite{hajipourIReEnReverseEngineeringBlackBox2021, menguyBlackboxCodeAnalysis2023},
and network protocol inference \autocite{luoDynPREProtocolReverse}.

Traditional model learning techniques,
such as those demonstrated by Muzammil et al. \autocite{shahbazAnalysisTestingBlackbox2014},
often focus on automatically inferring finite state machines.
Similarly, the reverse engineering techniques applied by Walkinshaw et al. \autocite{walkinshawReverseEngineeringSoftwareBehavior2013}
extract behavioral models through dynamic analysis.
These methods have proven effective for systems with discrete and well-defined input/output alphabets.

However, these classical approaches
face significant limitations when applied to modern conversational agents.
The infinite input space of natural language,
the non-deterministic nature of \ac{LLM}-powered systems,
and the complex, context-dependent state of a conversation
make traditional model learning techniques inadequate.
To our knowledge,
no prior work has successfully adapted these principles
to automatically generate comprehensive, functional models of chatbots
for the purpose of synthesizing test conversation profiles
in a pure black-box setting.

\subsection{Methodologies for Chatbot Testing}

The field of chatbot testing has evolved along several distinct paths,
each addressing different aspects of the validation challenge.
A comprehensive survey by Ren et al. \autocite{renEvaluationTechniquesChatbot2019} highlights the difficulties
in defining appropriate metrics and methodologies for these complex systems.

\subsubsection{Manual and Corpus-Based Testing}

The earliest and most direct approaches to chatbot testing
rely on manual effort and existing conversation corpora.
Manual testing, while essential for assessing usability,
is resource-intensive and difficult to scale.
A recent example of manual testing in chatbot development is GastroBot,
a \ac{RAG} chatbot fine-tuned
to answer gastrointestinal disease questions,
that during their evaluation, manual assesment was employed \autocite{zhouGastroBotChineseGastrointestinal2024},
highlighting the persistence of manual methods.

To introduce automation, frameworks like Bottester
\autocite{vasconcelosBottesterTestingConversational2017}
use existing Q\&A corpora.
While this provides a structured testing capability,
it is fundamentally dependent
on the availability and quality of a pre-existing dataset.
Similarly, commercial platforms like Cyara \autocite{CyaraBotium}
and Rasa's testing framework \autocite{RasaTest2025}
require the manual specification of test conversations and expected outcomes.
These approaches are primarily confirmatory,
designed to verify known behaviors rather than explore the unknown,
and they struggle to scale to the dynamic nature of modern agents.

\subsubsection{Static Analysis and White-Box Testing}

For scenarios where source code is available,
white-box techniques offer more rigorous validation.
Cuadrado et al. \autocite{cuadradoIntegratingStaticQuality2024}
propose static quality analysis techniques
that inspect the structural properties of a chatbot's implementation.
To assess test adequacy, Cañizares et al.
\autocite{canizaresCoveragebasedStrategiesAutomated2024}
develop coverage-based strategies that
require access to the chatbot's internal structure to compute metrics.

Mutation testing, a powerful technique for assessing test suite quality,
has also been adapted for chatbots.
Gómez-Abajo et al. \autocite{gomez-abajoMutationTestingTaskOriented2024}
propose mutation operators specifically for task-oriented chatbots like Taskyto \autocite{sanchezcuadradoAutomatingDevelopmentTaskoriented2024},
while Urrico et al. \autocite{urricoMutaBotMutationTesting2024} introduce MutaBot,
a dedicated mutation testing framework for platforms like Dialogflow \autocite{Dialogflow},
While these approaches provide rigorous validation,
their requirement for source code access
fundamentally limits their applicability to deployed systems
that must be treated as black boxes.

\subsection{User Simulation for Automated Testing}

User simulation has emerged as a key strategy to
address the scalability challenges of chatbot testing
by automatically generating realistic user interactions.
The most recent approaches employ generative \acl{AI},
especially \acp {LLM}.

\subsubsection{Traditional and Corpus-Driven Simulation}

Early user simulation approaches
relied on statistical models and existing corpora.
Griol et al. \autocite{griolAutomaticDialogSimulation2013}
employed neural networks trained on dialogue corpora
to suggest user utterances.
The user simulation capabilities within Bottester
\autocite{vasconcelosBottesterTestingConversational2017}
are also configured with Q\&A corpora
and compute metrics on satisfaction and correctness.
The primary limitation of these methods is
their dependency on large, relevant datasets,
which may not be available or cover all necessary scenarios.

\subsubsection{LLM-Based User Simulation}

The arrival of \acp{LLM} has enabled a new generation
of highly flexible and realistic user simulators.
Researchers have demonstrated the ability
to simulate users with specific personality traits and behaviors.
For example, Ferreira et al. \autocite{ferreiraMultitraitUserSimulation2024}
generate profiles with traits like engagement and verbosity,
while Sekulic et al. \autocite{sekulicSimulatingConversationalSearch2024}
simulate users with varying levels of patience and politeness for conversational search.
Frameworks like CoSearcher \autocite{salleStudyingEffectivenessConversational2021}
also allow for tuning user cooperativeness.
These works prove the principle of creating diverse, persona-driven simulated users.

Other approaches focus on specific conversational behaviors.
Kiesel et al. \autocite{kieselSimulatingFollowUpQuestions2024}
simulate follow-up questions,
and the followQG framework \autocite{bImprovingAsynchronousInterview2021}
uses trained models to generate contextually relevant continuations.
More advanced frameworks leverage \acp{LLM} for even more complex tasks.
The Kaucus simulator \autocite{dholeKAUCUSKnowledgeAugmented2024}
incorporates external knowledge via retrieval augmentation,
and Terragni et al. \autocite{terragniInContextLearningUser2023}
generate user utterances directly from high-level goal descriptions.
Bandlamudi et al. \autocite{bandlamudiFrameworkEnableTest2024}
employ a dual-\ac{LLM} approach where
one \ac{LLM} simulates the user and
another judges the chatbot's response.
Finally, Wit \autocite{dewitLeveragingLargeLanguage2024}
demonstrates the practicality of using commercial APIs like ChatGPT
for low-cost testing of rule-based agents.

\subsubsection{The Profile Generation Bottleneck}
Despite the remarkable progress in creating sophisticated user simulators,
a critical challenge remains: the profile generation bottleneck.
The SENSEI simulator \autocite{delaraSensei},
used in this research, exemplifies this issue.
It is a powerful tool capable of executing highly detailed test profiles,
but its effectiveness is entirely dependent on the quality of those profiles.
Across the state of the art,
these essential input profiles are either created manually,
a process that is time-consuming and does not scale,
or generated from generic descriptions
that lack grounding in the specific functionalities of the chatbot under test.
This creates a significant research gap
for a method that can automatically synthesize
rich, detailed, and targeted user profiles
based on a discovered model of the chatbot's actual capabilities.

\subsection{Summary and Identified Research Gaps}
Our review of the state of the art
reveals that while many valuable contributions have been made,
significant limitations persist.
Current approaches often require extensive manual effort,
are designed for specific technologies,
or necessitate access to source code,
restricting their generalizability.
The dependency on pre-existing corpora
further limits the applicability
of many simulation and testing techniques.

This analysis identifies three primary research gaps in the current literature:
\begin{enumerate}
    \item \textbf{A Lack of Fully Automated, Framework-Agnostic Black-Box Testing:}
      There is a pressing need for a testing methodology
      that can operate on any deployed chatbot in a fully automated manner,
      without requiring source code, manually written test scripts or pre-existing corpora.

    \item \textbf{An Unsolved Profile Generation Bottleneck:}
      The potential of advanced user simulators
      is currently constrained by the lack of an automated method
      to generate detailed, realistic test profiles
      that are specifically tailored to the discovered functionalities
      of the chatbot being tested.

    \item \textbf{The Absence of Applied Model Inference for Chatbot Testing:}
      The established principles of black-box model learning
      have not yet been effectively adapted and applied
      to the unique challenges of conversational \ac{AI}
      to automatically infer functional models
      for the purpose of test case generation.
\end{enumerate}

This thesis directly addresses these interconnected gaps.
We propose \ac{TRACER}, a novel framework
that provides a fully automated black-box method
for chatbot model learning and test profile generation.
By requiring only \ac{API} access to a deployed chatbot,
\ac{TRACER} overcomes the limitations of existing approaches
and provides a comprehensive, end-to-end solution
for the automated testing of modern conversational agents.
