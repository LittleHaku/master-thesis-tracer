% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Background and State of the Art}\label{chapter:state_of_the_art}

%TODO: Hacer una intruducción al capítulo

\section{Background}

\subsection{Conversational Agents}

Conversational agents, commonly referred to as chatbots,
are software systems designed to interact with users through natural language dialogue.
These systems have evolved from simple rule-based programs that followed predefined conversation flows
to sophisticated AI-powered agents capable of understanding context, maintaining conversational state, and generating human-like responses.

Modern conversational agents can be categorized into two main types
given the domain and range of their capabilities.
\begin{itemize}
  \item \textbf{Task-oriented:} on one hand we have the task-oriented chatbots,
  these are designed to assist users in completing specific tasks, such as booking appointments, processing orders, or providing customer support.
  These systems typically follow structured conversation flows
and maintain explicit state management to track task progress.
  Examples of these chatbots are Taskyto \autocite{sanchezcuadradoAutomatingDevelopmentTaskoriented2024} or UAM's assistant Ada \autocite{AdaUAM}.

  \item \textbf{Open-domain:}
  on the other hand, open-domain chatbots
  engage in general conversation without specific task constraints,
  aiming to provide informative, helpful, or entertaining interactions across a wide range of topics.
  These are chatbots like ChatGPT \autocite{ChatGPT} or Gemini \autocite{GoogleGemini}.
\end{itemize}

The development of these conversational agents
has beeen facilitated by various frameworks and platforms.
\begin{itemize}
  \item \textbf{Intent-based frameworks:}
    these frameworks such as Google's Dialogflow \autocite{Dialogflow} or Rasa \autocite{Rasa2020}
    enable developers to define conversation flow through intents, utterances, and responses.
    These platforms have low latency and deterministic behavior
    but are very rigid, struggle to scale,
    and to work properly require a big corpus to be trained on.

  \item \textbf{Multi-agent programming environments:}
    these systems like LangGraph \autocite{LangGraph} or Microsoft's AutoGen \autocite{AutoGen},
    allow for the creating of complex conversational systems
    where multiple \ac{AI} agents collaborate to process the user's request.
    These frameworks make use of the capabilities of \acp{LLM}.
    While they are less rigid than the previous ones,
    they can suffer from hallucinations, 
    higher latency, and since they are not deterministic,
    getting out of the scope, and thus, making it harder to test it.
\end{itemize}

\subsection{\aclp{LLM}}

\aclp{LLM} represent a significant advancement in \acl{NLP},
enable conversational agents to understand and generate human-like text
without explit programming of conversational rules like in intent-based frameworks.
These models, trained on a vast ammount of text data,
have demonstrated remarkable capabilities in
language understanding \autocite{liEnhancingNaturalLanguage2024}, generation, and reasoning across diverse domains.

The integration of \acp{LLM} into conversational agents
has transformed the way humans interacts with computers.
Unlike traditional rules-based systems that rely on predefined patterns and responses,
\ac{LLM}-powered chatbots can engage in natural conversations,
even keeping context about what the user said before.
However, this flexibility comes with challenges,
specially for testing and validation.
The non-deterministic natura of \acp{LLM} means that
identical inputs may produce different outputs across multiple interactions,
making traditional testing approaches inadequate for testing and validating them.

The just mentioned behavior exhibited by \ac{LLM}-powered systems
further complicates testing efforts.
These systems can demonstrate capabilities that were not explicitly programmed,
making it difficult to predict all possible conversation paths and outcomes.
This unpredictability necessitates new approaches to testing
that can systematically explore the space of possible interactions
and validate system behavior across diverse scenarios.

\subsection{Black-box Testing}

Black-box testing is a software testing methodology
where the internal structure, implementation details, and source code of the system under test
are unknown or inaccessible to the tester.
This approach focuses on validating system behavior based solely on inputs and outputs,
treating the system as an opaque "black box."

In the context of conversational agents,
black-box testing presents an interesting opportunity.
The accessibility advantage of black-box testing
is particularly relevant for deployed chatbots,
where users and testers typically interact with systems
through APIs or web interfaces without access to underlying code or configuration.
This mirrors real-world usage scenarios
and enables testing of production systems
without requiring special access privileges or development environment setup.


However, black-box testing of conversational agents faces unique challenges.
The exploration problem involves
systematically discovering the full range of functionalities
and conversation paths supported by the chatbot.
Unlike traditional software systems with well-defined APIs,
conversational agents accept natural language input,
making the input space virtually infinite.
The validation challenge requires determining
whether chatbot responses are correct, appropriate, and helpful
without access to specifications or expected behavior definitions.

% no se si esta seccion es un poco repetitiva
\subsection{\aclp{DSL} and Development Frameworks}

The heterogeneous nature of chatbot development
has led to the emergence of various \aclp{DSL} and frameworks
tailored for conversational agent creation.
Taskyto \autocite{sanchezcuadradoAutomatingDevelopmentTaskoriented2024} represents one such DSL specifically designed for task-oriented chatbot development,
providing abstractions that simplify the specification of
conversation flows, state management, and integration with external services.

LangGraph \autocite{LangGraph} exemplifies the multi-agent approach
to conversational system development,
enabling the creation of complex workflows
where multiple \ac{LLM}-powered agents collaborate to handle user requests.
This framework provides graph-based orchestration of agent interactions,
allowing for sophisticated conversation patterns
that can involve multiple reasoning steps, external tool usage, and dynamic response generation.

The diversity of these development approaches
creates significant challenges for testing methodologies.
Each framework imposes different constraints on
conversation structure, state management, and response generation.
A comprehensive testing approach must be framework-agnostic,
capable of validating chatbots 
regardless of their underlying implementation technology.

\section{State of the Art}
